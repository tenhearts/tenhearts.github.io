<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> | Kexin Shi (石可心)</title> <meta name="author" content="Kexin Shi"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://tenhearts.github.io/pvcnn.html"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Kexin Shi (石可心)</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <section class="hero"> <div class="hero-body"> <div class="container is-max-desktop"> <div class="column has-text-centered"> <h1 align="center" class="title is-1 publication-title"><b>Efficient Spatio-Temporal Processing<br> of Event Data</b></h1> <div class="column is-full_width"> </div> <br> <div align="center" class="is-size-5 publication-authors"> <h5 align="center" class="title is-1 publication-title"> <b> <a href="https://tenhearts.github.io">Kexin Shi</a>     <span class="author-block"> <a href="https://github.com/kaikai23?tab=repositories" rel="external nofollow noopener" target="_blank">Yifei Liu</a></span>     <span class="author-block"> <a href="https://magehrig.github.io/" rel="external nofollow noopener" target="_blank">Mathias Gehrig</a></span>     <span class="author-block"> <a href="https://messikommernico.github.io/" rel="external nofollow noopener" target="_blank">Nico Messikommer</a></span>     <span class="author-block"> <a href="https://rpg.ifi.uzh.ch/people_scaramuzza.html" rel="external nofollow noopener" target="_blank">Davide Scaramuzza</a> </span> </b> </h5> <h5> <span class="author-block"><a href="https://rpg.ifi.uzh.ch/index.html" rel="external nofollow noopener" target="_blank">Robotics and Perception Group, UZH &amp; ETHz</a></span> </h5> </div> <br> </div> </div> </div> </section> </div> <section class="section"> <div class="container is-max-desktop"> <div align="center"> <a href="https://dsec.ifi.uzh.ch/" rel="external nofollow noopener" target="_blank"><img src="assets/img/mp.gif" width="90%" class="center"></a> </div> <br><hr> <div class="columns is-centered has-text-centered"> <div class="column is-four-fifths"> <br> <h2 align="center" class="title is-3"><b>Abstract</b></h2> <div class="content has-text-justified"> <p> <b>TL;DR: We propose a point-voxel-based method to process event data in both classification task and optical flow regression task.</b> </p> <p> Event cameras are novel sensors that record a stream of asynchronous events and offer advantages of high dynamic range and no motion blur. Events can be converted to voxel grids and be processed by 2D or 3D Convolutional Neural Networks, or be directly processed by point-based model (i.e. PointNet). We want to investigate what are the pros and cons between these two types of models and try to combine the pros of both. By fairly comparing them within the same datasets and tasks, and within the similar preprocessing methodology, we show that the combination point-voxel-based method can get better performance than both voxel-based models and point-based models. </p> <br> </div> </div> </div> </div> </section> <section class="section"> <div class="container is-max-desktop"> <div class="columns is-centered has-text-centered"> <div class="column is-four-fifths"> <hr> <br> <h2 align="center" class="title is-3"><b>Key Idea</b></h2> <br> <div align="center"><img src="assets/img/pvcnn.png" width="90%" class="center"></div> <div class="content has-text-justified"> <br> <p> Recently, <a href="https://arxiv.org/abs/1907.03739" rel="external nofollow noopener" target="_blank">Point-Voxel CNN (PVCNN)</a> is proposed for processing 3D data (i.e. Lidar) and is proved to be more computationally efficient and faster than voxel-based or point-based NN models. We adapted the above PVCNN block on sparse event data directly and explored the best model architectures in classification and regression task.<br><br> </p> </div> </div> </div> <hr> <div class="columns is-centered has-text-centered"> <div class="column is-four-fifths"> <br> <h2 align="center" class="title is-3"><b>Research Questions</b></h2> <br> <div align="center"><img src="assets/img/pvcnn_rq.png" width="90%" class="center"></div> <div class="content has-text-justified"> <br> <p> <br> <b>RQ 1</b>: Event data is huge and noisy. How to preprocess and downsample it effectively? <br> <b>RQ 2</b>: What's the performances of voxel-based methods (2D CNN, 3D CNN), point-based methods (PointNet, PointNet++) and point-voxel-based method (PVCNN)? <br> <b>RQ 3</b>: In PVCNN block, is MLP part useful? <br> <b>RQ 4</b>: In PVCNN block, is devoxelization necessary? <br> <b>RQ 5</b>: What's the performances of Dense Conv and Sparse Conv? <br> </p> </div> </div> </div> <hr> <div class="columns is-centered has-text-centered"> <div class="column is-four-fifths"> <br> <h2 align="center" class="title is-3"><b>Methods</b></h2> <div align="center"><img src="assets/img/pvcnn_method.png" width="90%" class="center"></div> <div class="content has-text-justified"> <p> </p> <li> <b>Classification</b>: We adapt PVCNN blocks sequentially at different resolutions, and then aggragate information at different scales.</li> <li> <b>Regression</b>: Similarily to U-Net, we first downsample by PVCNN blocks, and then upsample to propagate context information.</li> </div> <br> </div> </div> <hr> <div class="columns is-centered has-text-centered"> <div class="column is-four-fifths"> <br> <h2 align="center" class="title is-3"><b>Conclusions</b></h2> <div class="content has-text-justified"> <p> <br> <b>RQ 1</b>: The less points, the faster speed, but also the lower performance. With similar number of points, data-dependent downsample performs better than random sample. <br> <b>RQ 2</b>: Point-based method is inaccurate and slow. Point-Voxel method has the best performance with sacrificing some speed. Voxel-based method (3D) is either bad at performance or speed. The most time-consuming part is 3D convolution. Frame-based method (2D) has a good trade-off between performance and speed. <br> <b>RQ 3</b>: No. MLP can only bring noises even we increase the number of layers. Point features generated by MLP are not useful for events data. <br> <b>RQ 4</b>: Yes. Compared with passing voxel-based features between different resolutions, passing point-based features has a distinct improvement in performance. <br> <b>RQ 5</b>: Sparse convolution within the PVConv structure is faster, but with worse performance. </p> </div> <br> </div> </div> </div> </section> </body> </html><html> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Kexin Shi. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.Last updated: July 13, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </html>