---
layout: default
---

<!-- <!DOCTYPE html> -->
<html>
<!-- <head>
  <meta charset="utf-8">
  <meta name="description"
        content="OpenScene: 3D Scene Understanding with Open Vocabularies">
  <meta name="keywords" content="OpenScene">
  <meta name="viewport" content="width=device-width, initial-scale=1"> -->
  <!--for thumbnail-->
  <!-- <meta property="og:image" content="media/openscene/teaser.jpg">
  <meta property="og:url" content="https://pengsongyou.github.io/openscene">
  <meta property="og:description" content="3D Scene Understanding with Open Vocabularies">
  <title>OpenScene</title> -->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

<!-- <link rel="icon" type="image/png" href="media/openscene/logo.png"> 
<link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./media/nice-slam/css/bulma.min.css">
  <link rel="stylesheet" href="./media/nice-slam/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./media/nice-slam/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./media/nice-slam/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./media/nice-slam/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./media/nice-slam/js/fontawesome.all.min.js"></script>
  <script src="./media/nice-slam/js/bulma-carousel.min.js"></script>
  <script src="./media/nice-slam/js/bulma-slider.min.js"></script>
  <script src="./media/nice-slam/js/index.js"></script>
</head>
<body> -->

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://pengsongyou.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://pengsongyou.github.io/conv_onet">
            ConvONet - ECCV 2020
          </a>
          <a class="navbar-item" href="https://pengsongyou.github.io/sap">
            Shapt As Points - NeurIPS 2021
          </a>
          <a class="navbar-item" href="https://pengsongyou.github.io/nice-slam">
            NICE-SLAM - CVPR 2022
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- <div class="columns is-centered">
        <div class="column is-7 has-text-centered">
          <img src="media/nice-slam/nice-slam-logo2.png" alt="NICE-SLAM"/>
        </div>
      </div> -->
        <div class="column has-text-centered">
          <!-- <h1 class="title is-1 publication-title"><img src="media/nice-slam/like.png" width="90">NICE-SLAM&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>Neural Implicit Scalable Encoding for SLAM</h1> -->
          <!-- <h1 class="title is-1 publication-title"><img src="media/openscene/logo.png" width="70">OpenScene&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</h1> -->
          <h1 align="center" class="title is-1 publication-title"><b>Efficient Spatio-Temporal Processing<br> of Event Data</b></h1>
          <div class="column is-full_width">
            <!-- <h2 align="center" class="title is-4">Master Project</h2> -->
          </div>
          <br>
          <div align="center" class="is-size-5 publication-authors">
              <!-- <span class="author-block"> -->
                <h5 align="center" class="title is-1 publication-title">
                  <b>
                <!-- <a href="https://pengsongyou.github.io">Songyou Peng</a><sup>1,2,3 * </sup></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -->
                <a href="https://tenhearts.github.io">Kexin Shi</a></span></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <!-- </span> -->
              <span class="author-block">
              <a href="https://github.com/kaikai23?tab=repositories">Yifei Liu</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
            <span class="author-block">
              <a href="https://magehrig.github.io/">Mathias Gehrig</a></span></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://messikommernico.github.io/">Nico Messikommer</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://rpg.ifi.uzh.ch/people_scaramuzza.html">Davide Scaramuzza</a>
            </span>
            </b>
                </h5>
            
            <!-- <h6><sup>*</sup> Equal Contribution</h6>         -->
            <h5>
            <span class="author-block"><a href="https://rpg.ifi.uzh.ch/index.html">Robotics and Perception Group, UZH & ETHz</a></span>
            </h5>
            
          </div>
          <br>
          <!-- <div class="is-size-5 publication-authors"> -->
            <!-- <h5 align="center"> --> 
            <!-- <span class="author-block"><sup>1</sup>Google Research</span>&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>ETH Zurich</span>&nbsp;&nbsp;
            <span class="author-block"><sup>3</sup>MPI for Intelligent Systems, TÃ¼bingen</span>&nbsp;&nbsp;<br>
            <span class="author-block"><sup>4</sup>Waymo LLC</span>&nbsp;&nbsp;
            <span class="author-block"><sup>5</sup>Simon Fraser University</span> -->
            
          <!-- </h5> -->
          <!-- </div> -->

          <!-- <div class="column has-text-centered">
            <div class="publication-links"> -->
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2211.15654" target="_blank"
                   class="button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- Supp Link. -->
              <!-- <span class="link-block">
                <a href="xxx" target="_blank"
                   class="button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supplementary Material</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://youtu.be/jZxCLHyDJf8"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
               <!-- <span class="link-block">
                <a href="https://github.com/pengsongyou/openscene" target="_blank"
		   class="external-link button is-normal is-rounded is-dark" style="background-color: #808080">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span >Code</span>
                  </a>
              </span> 
            </div> -->

          </div>
        </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="media/openscene/teaser.jpg" class="center"/>
      <br><br>
      <h2 class="subtitle has-text-centered">
      <strong>OpenScene</strong> is a zero-shot approach to perform novel 3D scene understanding tasks with open-vocabulary queries.
    </h2>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <div align="center"><a href="https://dsec.ifi.uzh.ch/"><img src="assets/img/mp.gif" width="90%" class="center"/></a>
      <!-- <br>
      <p>We use <a href="https://dsec.ifi.uzh.ch/">DSEC</a> dataset for optical flow regression task.</p> -->
    </div>
        <!-- Paper video. -->
        <!-- <div class="columns is-centered has-text-centered"> -->
          <!-- <div class="column is-four-fifths"> -->
            <!-- <div class="column is-full_width">
            <h2 class="title is-3">Explanatory Video</h2>
            <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/jZxCLHyDJf8?rel=0&amp;showinfo=0"
                      frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
                <!-- <video id="dollyzoom" controls loop width="100%">
                  <source src="media/openscene/OpenScene_video_full_compressed.mp4"
                          type="video/mp4">
                </video> -->
            <!-- </div>
          </div>
        </div> -->
        <!--/ Paper video. -->
      
    <br><hr>
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <br>
        <h2 align="center" class="title is-3"><b>Abstract</b></h2>
        <div class="content has-text-justified">
          <p>
            <b>TL;DR: We propose a point-voxel-based method to process event data in both classification task and 
              optical flow regression task.</b>
          </p>
          <p>
            Event cameras are novel sensors that record a stream of asynchronous events
            and offer advantages of high dynamic range and no motion blur. Events can be
            converted to voxel grids and be processed by 2D or 3D Convolutional Neural Networks, or
            be directly processed by point-based model (i.e. PointNet). We want to investigate what are 
            the pros and cons between these two types of models and try to combine the pros of both.
            By fairly comparing them within the same datasets and tasks, and within the
            similar preprocessing methodology, we show that the combination point-voxel-based method 
            can get better performance than both voxel-based models and point-based models.
          </p>
          <br>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Key Idea -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <hr>
        <br>
        <h2 align="center" class="title is-3"><b>Key Idea</b></h2>
        <br>
        <div align="center"><img src="assets/img/pvcnn.png" width="90%" class="center"/></div>
        <div class="content has-text-justified">
          <br>  
          <p>
            Recently, <a href="https://arxiv.org/abs/1907.03739">Point-Voxel CNN (PVCNN)</a> is proposed for processing 3D data (i.e. Lidar) and is proved to be more computationally efficient and faster
            than voxel-based or point-based NN models. We adapted the above PVCNN block on sparse event data directly and explored the best model architectures in classification 
            and regression task.<br><br>
          </p>
        </div>
      </div>
    </div>
    <hr>
    
      <!-- Method -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <br>
          <h2 align="center" class="title is-3"><b>Research Questions</b></h2>
          <br>
          <div align="center"><img src="assets/img/pvcnn_rq.png" width="90%" class="center"/></div>
          <div class="content has-text-justified">
            <br>  
            <p>
              <!-- <strong>How to produce text-image-3D co-embeddings?</strong> -->
              <br>  
              <b>RQ 1</b>: Event data is huge and noisy. How to preprocess and downsample it effectively?
              <br>  
              <b>RQ 2</b>: What's the performances of voxel-based methods (2D CNN, 3D CNN), point-based methods (PointNet, PointNet++) and point-voxel-based method (PVCNN)?
              <br>  
              <b>RQ 3</b>: In PVCNN block, is MLP part useful?
              <br>
              <b>RQ 4</b>: In PVCNN block, is devoxelization necessary?
              <br>
              <b>RQ 5</b>: What's the performances of Dense Conv and Sparse Conv?
              <br>
            </p>
          </div>
        </div>
      </div>
      <hr>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <br>
          <h2 align="center" class="title is-3"><b>Methods</b></h2>
          <!-- <br> -->
          <div align="center"><img src="assets/img/pvcnn_method.png" width="90%" class="center"/></div>
          <div class="content has-text-justified">
            <!-- <br>   -->
            <p>
              <li><b>Classification</b>: We adapt PVCNN blocks sequentially at different resolutions, and then aggragate information at different scales.</li>
              <li><b>Regression</b>: Similarily to U-Net, we first downsample by PVCNN blocks, and then upsample to propagate context information.</li>
            </p>
          </div>
          <br>
        </div>
      </div>
      <hr>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <br>
          <h2 align="center" class="title is-3"><b>Conclusions</b></h2>
          <!-- <br> -->
          <!-- <div align="center"><img src="assets/img/pvcnn_rq.png" width="90%" class="center"/></div> -->
          <div class="content has-text-justified">
            <!-- <br>   -->
            <p>
              <!-- <strong>How to produce text-image-3D co-embeddings?</strong> -->
              <br>  
              <b>RQ 1</b>: The less points, the faster speed, but also the lower performance. With similar number of points, data-dependent downsample performs better than random sample.
              <br>  
              <b>RQ 2</b>: Point-based method is inaccurate and slow. Point-Voxel method has the best performance with sacrificing some speed. Voxel-based method (3D) is either 
              bad at performance or speed. The most time-consuming part is 3D convolution. Frame-based method (2D) has a good trade-off between performance and speed.
              <br>  
              <b>RQ 3</b>: No. MLP can only bring noises even we increase the number of layers. Point features generated by MLP are not useful for events data.
              <br>
              <b>RQ 4</b>: Yes. Compared with passing voxel-based features between different resolutions, passing point-based features has a distinct improvement in performance.
              <br>
              <b>RQ 5</b>: Sparse convolution within the PVConv structure is faster, but with worse performance.
            </p>
          </div>
          <br>
        </div>
      </div>
      


</div>
</section>




</body>
</html>