---
layout: default
---

<!DOCTYPE html>
<html>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- <div class="columns is-centered">
        <div class="column is-7 has-text-centered">
          <img src="media/nice-slam/nice-slam-logo2.png" alt="NICE-SLAM"/>
        </div>
      </div> -->
        <div class="column has-text-centered">
          <!-- <h1 class="title is-1 publication-title"><img src="media/nice-slam/like.png" width="90">NICE-SLAM&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>Neural Implicit Scalable Encoding for SLAM</h1> -->
          <!-- <h1 class="title is-1 publication-title"><img src="media/openscene/logo.png" width="70">OpenScene&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</h1> -->
          <h1 align="center" class="title is-1 publication-title"><b>Learning Perception-Aware Agile Flight in Cluttered Environments</b></h1>
          <div class="column is-full_width">
            <!-- <h2 align="center" class="title is-4">Master Project</h2> -->
          </div>
          <br>
          <div align="center" class="is-size-5 publication-authors">
              <!-- <span class="author-block"> -->
                <h5 align="center" class="title is-1 publication-title">
                  <b>
                <!-- <a href="https://pengsongyou.github.io">Songyou Peng</a><sup>1,2,3 * </sup></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -->
                <a href="https://yun-long.github.io/">Yunlong Song<sup>*1</sup></a></span></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <!-- </span> -->
              <span class="author-block">
                <a href="https://tenhearts.github.io/">Kexin Shi<sup>*1</sup></a></span></span>&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
            <span class="author-block">
              <a href="https://scholar.google.cz/citations?user=nBkNn-EAAAAJ&hl=cs">Robert Penicka<sup>2</sup></a></span></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://people.inf.ethz.ch/pomarc/">Davide Scaramuzza<sup>1</sup></a>
            </span>
            </b>
            <!-- <span class="author-block"><a href="https://rpg.ifi.uzh.ch/index.html">Robotics and Perception Group, UZH & ETHz</a></span> -->
            </h5>
          </div>
          <div class="is-size-5 publication-authors">
            <h5 align="center"> 
            <span class="author-block"><sup>1</sup>University of Zurich and ETH Zurich</span>&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Czech Technical University</span>&nbsp;&nbsp;
            <!-- <span class="author-block"><sup>3</sup>MPI for Intelligent Systems, Tübingen</span>&nbsp;&nbsp;<br>
            <span class="author-block"><sup>4</sup>Waymo LLC</span>&nbsp;&nbsp;
            <span class="author-block"><sup>5</sup>Simon Fraser University</span> -->
            
          </h5>
          </div>
          <h6 align="center"><sup>*</sup> Equal Contribution</h6>
          <br>
          <h4 align="center"><b>ICRA 2023</b></h4>
          <br>
          <h4>
          <div class="column has-text-centered">
            <div align="center" class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2210.01841" target="_blank"
                   class="button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>&nbsp;&nbsp;
              </span>
              <!-- Supp Link. -->
              <!-- <span class="link-block">
                <a href="xxx" target="_blank"
                   class="button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supplementary Material</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=9q059CFGcVA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
               <!-- <span class="link-block">
                <a href="https://github.com/pengsongyou/openscene" target="_blank"
		   class="external-link button is-normal is-rounded is-dark" style="background-color: #808080">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span >Code</span>
                  </a>
              </span> 
            </div> -->

          </div>
        </h4>
        </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="media/openscene/teaser.jpg" class="center"/>
      <br><br>
      <h2 class="subtitle has-text-centered">
      <strong>OpenScene</strong> is a zero-shot approach to perform novel 3D scene understanding tasks with open-vocabulary queries.
    </h2>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <br>
    <!-- <div align="center"><img src="assets/img/agileflight.gif" width="100%" class="center"/></div> -->
        <!-- Paper video. -->
        <!-- <div class="columns is-centered has-text-centered"> -->
          <!-- <div class="column is-four-fifths"> -->
            <!-- <div class="column is-full_width">
            <h2 class="title is-3">Explanatory Video</h2>
            <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/jZxCLHyDJf8?rel=0&amp;showinfo=0"
                      frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
                <!-- <video id="dollyzoom" controls loop width="100%">
                  <source src="media/openscene/OpenScene_video_full_compressed.mp4"
                          type="video/mp4">
                </video> -->
            <!-- </div>
          </div>
        </div> -->
        <!--/ Paper video. -->
      
    <hr>
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <br>
        <h2 align="center" class="title is-3"><b>Abstract</b></h2>
        <div class="content has-text-justified">
          <br>
          <p>
            <b>TL;DR: We  propose a perception-aware, minimum-time, vision-based navigation method to fly a quadrotor through a cluttered environment, which combines reinforcement learning 
              and imitation learning by leveraging a learning-by-cheating framework .</b>
          </p>
          <p>
            Recently, neural control policies have outperformed existing model-based planning-and-control methods for 
            autonomously navigating quadrotors through cluttered environments in minimum time. However, they are not perception aware, 
            a crucial requirement in vision-based navigation due to the camera's limited field of view and the underactuated nature of a quadrotor. 
            We propose a method to learn neural network policies that achieve perception-aware, minimum-time flight in cluttered environments. 
            Our method combines imitation learning and reinforcement learning (RL) by leveraging a privileged learning-by-cheating framework. 
            Using RL, we first train a perception-aware teacher policy with full-state information to fly in minimum time through cluttered environments. 
            Then, we use imitation learning to distill its knowledge into a vision-based student policy that only perceives the environment via a camera. 
            Our approach tightly couples perception and control, showing a significant advantage in computation speed (10x faster) and success rate. 
            We demonstrate the closed-loop control performance using a physical quadrotor and hardware-in-the-loop simulation at speeds up to 50km/h.
          </p>
          <br>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-four-fifths"> -->
        <div class="column is-full_width">
          <hr><br>
        <h2 align="center" class="title is-3"><b>Video</b></h2>
        <br>
        <div align="center" class="video-container">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/9q059CFGcVA" title="YouTube video player" frameborder="0" 
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <br>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Key Idea -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <hr>
        <br>
        <h2 align="center" class="title is-3"><b>Overview</b></h2>
        <br>
        <div align="center"><img src="assets/img/training.png" width="100%" class="center"/></div>
        <br>
        <p>
          <b>Training</b>:
          We first train a state-based teacher policy using model-free deep reinforcement learning, in which the policy has access to privileged information about the vehicle’s state and 
          its surrounding environment. This teacher policy is then distilled into a vision-based student policy that does not rely on privileged information. Training is finished in 
          <a href="https://uzh-rpg.github.io/flightmare/">Flightmare</a>.
        </p>
        <!-- <div class="content has-text-justified"> -->
          <br>  
          <div align="center"><img src="assets/img/deployment.png" width="100%" class="center"/></div>
        <br>
        <p>
          <b>Deployment</b>: 
          We deploy the vision-based policy in real world via <a href="https://www.science.org/doi/10.1126/scirobotics.abl6259">hardware-in-the-loop (HITL) simulation</a> directly, 
          which consists of flying a physical quadrotor in a motion-capture system while observing virtual photorealistic environments that are updated in real-time. <br><br>
        </p>
        </div>

      </div>
    </div>
    <hr>
    
      <!-- Method -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <br>
          <h2 align="center" class="title is-3"><b>Learning State-based Teacher Policy</b></h2>
          <!-- <br> -->
          <!-- <div align="center"><img src="assets/img/pvcnn_rq.png" width="90%" class="center"/></div> -->
          <div class="content has-text-justified">
            <br>  
            <p>
              <video autoplay loop muted src="assets/img/teacher.mp4" alt="sym" width="100%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black"></video>
            </p>
          </div>
        </div>
        <br>
      </div>
      <hr>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <br>
          <h2 align="center" class="title is-3"><b>Learning Vision-based Student Policy</b></h2>
          <br>
          <video autoplay loop muted src="assets/img/student.mp4" alt="sym" width="100%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black"></video>
          <div class="content has-text-justified">
            <!-- <br>   -->
            <!-- <p>
              
            </p> -->
          </div>
          <br>
        </div>
      </div>
      <hr>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <br>
          <h2 align="center" class="title is-3"><b>Real-World Deployment</b></h2>
          <!-- <br> -->
          <!-- <div align="center"><img src="assets/img/pvcnn_rq.png" width="90%" class="center"/></div> -->
          <!-- <div class="content has-text-justified"> -->
            <br>  
            <!-- <div align="center"><img src="assets/img/agileflight.gif" width="100%" class="center"/></div> -->
            <video autoplay loop muted src="assets/img/mix.mp4" alt="sym" width="100%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black"></video>
          </div>
          <br>
        </div>
      </div>
      

      <!-- <section class="section" id="BibTeX"> -->
        <hr>
        <div class="container is-max-desktop content">
          <h2 align="center" class="title is-3"><b>BibTex</b></h2>
          <!-- <br> -->
          <pre><code>@misc{https://doi.org/10.48550/arxiv.2210.01841,
            doi = {10.48550/ARXIV.2210.01841},
            url = {https://arxiv.org/abs/2210.01841},
            author = {Song, Yunlong and Shi, Kexin and Penicka, Robert and Scaramuzza, Davide},
            keywords = {Robotics (cs.RO), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
            title = {Learning Perception-Aware Agile Flight in Cluttered Environments},
            publisher = {arXiv},
            year = {2022},
            copyright = {arXiv.org perpetual, non-exclusive license}
          }
        </code></pre>
        </div>
      <!-- </section> -->
      


</div>
</section>




</body>
</html>